{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xlsxwriter\n",
    "import datetime\n",
    "import string\n",
    "import pandas as pd\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(string_date):#converts a string from the format found in the json file to a datetime timedelta object\n",
    "    temp = string_date\n",
    "    temp = temp.replace(\"PT\",\"\")\n",
    "    temp = temp.replace(\"H\",\":\")\n",
    "    temp = temp.replace(\"M\",\":\")\n",
    "\n",
    "    if(len(temp)<=10):\n",
    "        temp = temp[:-1]\n",
    "    else:\n",
    "        temp = temp[:-2]\n",
    "    #print(temp)\n",
    "    try:\n",
    "        timestamp = datetime.datetime.strptime(temp, \"%H:%M:%S.%f\")\n",
    "    except:\n",
    "        try:\n",
    "            timestamp = datetime.datetime.strptime(temp, \"%M:%S.%f\")\n",
    "        except:\n",
    "            try:\n",
    "                timestamp = datetime.datetime.strptime(temp, \"%S.%f\")\n",
    "            except:\n",
    "                timestamp = datetime.datetime.strptime(temp, \"%M:%S\")\n",
    "    return datetime.timedelta(hours = timestamp.hour,  minutes = timestamp.minute, seconds = timestamp.second, microseconds = timestamp.microsecond)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def json_to_csv(filename, name_of_new_file = \"placeholder.xlsx\"):#creates 2 csv files based on the stream json files\n",
    "    with open(filename, 'r') as f:\n",
    "            datastore = json.load(f)\n",
    "            \n",
    "    datastore_length = len(datastore['value'])\n",
    "    actor_ids = list()\n",
    "    start_time = list()\n",
    "    end_time = list()\n",
    "    \n",
    "    for i in range(0,datastore_length):\n",
    "        y_length = 0\n",
    "        for y in datastore['value'][i]['events']:\n",
    "            y_length = len(y['start'])\n",
    "            start_time.append(y['start'])\n",
    "            end_time.append(y['end'])\n",
    "            actor_ids.append(y['eventData']['personId'])\n",
    "            \n",
    "    df = pd.DataFrame(list(zip(actor_ids, start_time, end_time)), \n",
    "               columns =['PersonId', 'Start_time','End_time']) \n",
    "    df['Start_time'] = df['Start_time'].map(lambda x: to_datetime(x))\n",
    "    df['End_time'] = df['End_time'].map(lambda x: to_datetime(x))\n",
    "    df['Total_time'] = df['End_time']-df['Start_time']\n",
    "    df.sort_values(by=['Start_time'])\n",
    "    #create second sheet of excel file\n",
    "    all_ids = list()\n",
    "    image_urls = list()\n",
    "    for i in range(0,datastore_length):\n",
    "        all_ids.append(datastore['value'][i]['id'])\n",
    "        image_urls.append(datastore['value'][i]['imageUrl'])\n",
    "    total_screentime = list()\n",
    "    for i in all_ids:\n",
    "        total_screentime.append(sum(df[df['PersonId']==i]['Total_time'].tolist(),datetime.timedelta()))\n",
    "    #print(total_screentime)\n",
    "    df2 = pd.DataFrame(list(zip(all_ids, image_urls,total_screentime)), columns = ['ActorId', 'Image_url','Total_ScreenTime'])\n",
    "    df.to_csv(name_of_new_file)\n",
    "    df2.to_csv(name_of_new_file+\"_aggregated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the movie to csv just run the json_to_csv function, the first parameter is the filename of the json file\n",
    "# you want to convert and the second parameter is the new filename without the .csv\n",
    "json_to_csv(\"JSON/dirty_harry_1.json\",\"dirty_harry_1_screentime\")\n",
    "json_to_csv(\"JSON/dirty_harry_2.json\",\"dirty_harry_2_screentime\")\n",
    "json_to_csv(\"JSON/dirty_harry_3.json\",\"dirty_harry_3_screentime\")\n",
    "json_to_csv(\"JSON/dirty_harry_4.json\",\"dirty_harry_4_screentime\")\n",
    "json_to_csv(\"JSON/dirty_harry_5.json\",\"dirty_harry_5_screentime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f4bf8da3944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtotal_screentime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtotal_screentime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PersonId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#print(total_screentime)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    '''\n",
    "     This function essentially convert the image url to \n",
    "     '<img src=\"'+ path + '\"/>' format. And one can put any\n",
    "     formatting adjustments to control the height, aspect ratio, size etc.\n",
    "     within as in the below example. \n",
    "    '''\n",
    "\n",
    "    return '<img src=\"'+ path + '\" style=max-height:124px;\"/>'\n",
    "\n",
    "with open(\"JSON/dirty_harry_1.json\", 'r') as f:\n",
    "            datastore = json.load(f)\n",
    "            \n",
    "datastore_length = len(datastore['value'])\n",
    "all_ids = list()\n",
    "image_urls = list()\n",
    "for i in range(0,datastore_length):\n",
    "    all_ids.append(datastore['value'][i]['id'])\n",
    "    image_urls.append(datastore['value'][i]['imageUrl'])\n",
    "    \n",
    "total_screentime = list()\n",
    "for i in all_ids:\n",
    "        total_screentime.append(sum(df[df['PersonId']==i]['Total_time'].tolist(),datetime.timedelta()))\n",
    "    #print(total_screentime)\n",
    "    \n",
    "df2 = pd.DataFrame(list(zip(all_ids, image_urls,total_screentime)), columns = ['ActorId', 'Image_url','Total_ScreenTime'])\n",
    "\n",
    "\n",
    "\n",
    "HTML(df2.to_html(escape=False ,formatters=dict(Image_url=path_to_image_html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
