{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "import requests\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOGUE_INDIA_BASE_URL = \"https://www.vogue.in/\"\n",
    "VOGUE_AMERICA_URL = \"https://www.vogue.com/\"\n",
    "INDIA_CATEGORIES = [\"fashion\",\"beauty\",\"news\"]\n",
    "AMERICA_CATEGORIES = [\"fashion\",\"beauty\",\"culture\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_url_generator(number_of_pages):\n",
    "    page_list = [\"?page=\"+str(i) for i in range(2,number_of_pages+1)]\n",
    "    page_list.insert(0,\"\")\n",
    "    return page_list\n",
    "\n",
    "NUMBER_OF_FASHION_PAGES = 280\n",
    "NUMBER_OF_BEAUTY_PAGES = 91\n",
    "NUMBER_OF_NEWS_PAGES = 73\n",
    "fashion_pages = page_url_generator(NUMBER_OF_FASHION_PAGES)\n",
    "beauty_pages = fashion_pages[:NUMBER_OF_BEAUTY_PAGES+1]\n",
    "news_pages = fashion_pages[:NUMBER_OF_NEWS_PAGES+1]\n",
    "fashion_page_urls = [VOGUE_INDIA_BASE_URL+INDIA_CATEGORIES[0]+i for i in fashion_pages]\n",
    "beauty_page_urls = [VOGUE_INDIA_BASE_URL+INDIA_CATEGORIES[1]+i for i in fashion_pages]\n",
    "news_page_urls = [VOGUE_INDIA_BASE_URL+INDIA_CATEGORIES[2]+i for i in fashion_pages]\n",
    "print(fashion_page_urls[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "def parse_page_articles(number_of_pages,urls_to_parse):\n",
    "    article_urls = []\n",
    "    for i in range(number_of_pages):\n",
    "        #print(i)\n",
    "        page = requests.get(urls_to_parse[i])\n",
    "        #page\n",
    "        main_soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        for link in main_soup.find_all('a'):\n",
    "            link_string = link.get('href')\n",
    "            if \"/content/\" in link_string:\n",
    "                article_urls.append(VOGUE_INDIA_BASE_URL+link_string[1:])\n",
    "    return article_urls\n",
    "fashion_articles = parse_page_articles(NUMBER_OF_FASHION_PAGES,fashion_page_urls)\n",
    "beauty_articles = parse_page_articles(NUMBER_OF_BEAUTY_PAGES,beauty_page_urls)\n",
    "news_articles = parse_page_articles(NUMBER_OF_NEWS_PAGES,news_page_urls)\n",
    "print(news_articles[0:2])\n",
    "print(len(fashion_articles))\n",
    "print(len(beauty_articles))\n",
    "print(len(news_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_article_content(list_of_article_urls): #returns list of text from articles\n",
    "    list_of_content = []\n",
    "    counter = 0\n",
    "    for i in list_of_article_urls:\n",
    "        print(counter)\n",
    "        article_page = requests.get(i)\n",
    "        sub_soup = BeautifulSoup(article_page.content, 'html.parser')\n",
    "        sub_soup.find_all('p')\n",
    "        article_content = []\n",
    "        for content in sub_soup.find_all('p'):\n",
    "            article_content.append(content.get_text())\n",
    "        article_content_string = \" \\n\".join(article_content)\n",
    "        list_of_content.append(article_content_string)\n",
    "        counter+=1\n",
    "    return list_of_content\n",
    "\n",
    "fashion_content = get_article_content(fashion_articles)\n",
    "beauty_content = get_article_content(beauty_articles)\n",
    "news_content = get_article_content(news_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('fashion_content', 'wb') as fp:\n",
    "    pickle.dump(fashion_content, fp)\n",
    "with open('beauty_content', 'wb') as fp:\n",
    "    pickle.dump(beauty_content, fp)\n",
    "with open('news_content', 'wb') as fp:\n",
    "    pickle.dump(fashion_content, fp)\n",
    "#to read it back    \n",
    "#with open ('fashion_content', 'rb') as fp:\n",
    "#    itemlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fashion_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_string = \" /n New Article\".join(fashion_content)\n",
    "beauty_string = \" /n New Article\".join(beauty_content)\n",
    "news_string = \" /n New Article\".join(news_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "with io.open(\"fashion.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(fashion_string)\n",
    "    \n",
    "with io.open(\"beauty.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(beauty_string)\n",
    "    \n",
    "with io.open(\"news.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(news_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.vogue.com/vogueworld/article/nushu-dj-collective-shanghai-china-amber-akilla-lhaga-koondhoor\n",
      "https://www.vogue.com/vogueworld/article/nushu-dj-collective-shanghai-china-amber-akilla-lhaga-koondhoor\n",
      "https://www.vogue.com/vogueworld/article/fka-twigs-red-bull-new-york-festival-park-avenue-armory-pole-dancing\n",
      "https://www.vogue.com/vogueworld/article/fka-twigs-red-bull-new-york-festival-park-avenue-armory-pole-dancing\n",
      "https://www.vogue.com/vogueworld/article/paloma-elsesser-lagos-homecoming\n",
      "https://www.vogue.com/vogueworld/article/paloma-elsesser-lagos-homecoming\n",
      "https://www.vogue.com/article/refine-slips-silk-dresses-skirts-london\n",
      "https://www.vogue.com/article/refine-slips-silk-dresses-skirts-london\n",
      "https://www.vogue.com/vogueworld/article/emily-ratajkowski-narciso-rodriguez-goddess-gown\n",
      "https://www.vogue.com/vogueworld/article/emily-ratajkowski-narciso-rodriguez-goddess-gown\n",
      "https://www.vogue.com/article/diary-of-a-model-suki-waterhouse-moschino-resort-2020-video\n",
      "https://www.vogue.com/article/diary-of-a-model-suki-waterhouse-moschino-resort-2020-video\n",
      "https://www.vogue.com/vogueworld/article/kate-middleton-queen-letizia-order-of-the-garter\n",
      "https://www.vogue.com/vogueworld/article/kate-middleton-queen-letizia-order-of-the-garter\n",
      "https://www.vogue.com/article/barbie-ferreira-latex-vex-clothing-mtv-movie-awards-look\n",
      "https://www.vogue.com/article/barbie-ferreira-latex-vex-clothing-mtv-movie-awards-look\n",
      "https://www.vogue.com/vogueworld/article/beach-vacation-outfit-ideas-menswear-style-inspiration\n",
      "https://www.vogue.com/vogueworld/article/beach-vacation-outfit-ideas-menswear-style-inspiration\n",
      "https://www.vogue.com/article/heidi-schreck-history-making-broadway-diary\n",
      "https://www.vogue.com/article/heidi-schreck-history-making-broadway-diary\n",
      "https://www.vogue.com/article/zendaya-cover-interview-june-2019\n",
      "https://www.vogue.com/article/zendaya-cover-interview-june-2019\n",
      "/article/vogue-podcast\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.vogue.com/fashion\")\n",
    "\n",
    "main_soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "for link in main_soup.find_all('a'):\n",
    "    link_string = link.get('href')\n",
    "    if link_string is not None:\n",
    "        if \"/article/\" in link_string or \"vogueworld/article/\" in link_string:\n",
    "            print(link_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
